{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af78c139",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "import tweepy\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import string\n",
    "import preprocessor as p\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee997f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting preprocessor\n",
      "  Downloading preprocessor-1.1.3.tar.gz (4.2 kB)\n",
      "Building wheels for collected packages: preprocessor\n",
      "  Building wheel for preprocessor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for preprocessor: filename=preprocessor-1.1.3-py3-none-any.whl size=4475 sha256=b59862cda2d1c7367b106686f8e518e6859342390f3df7e42781dab6fc8fffec\n",
      "  Stored in directory: /Users/gauribaraskar/Library/Caches/pip/wheels/e4/4e/bf/0ecf68aa10ee89d684d90437bd9f89ac19d5dc2921988bb59d\n",
      "Successfully built preprocessor\n",
      "Installing collected packages: preprocessor\n",
      "Successfully installed preprocessor-1.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip3 install preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1f65386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter credentials\n",
    "# Obtain them from your twitter developer account\n",
    "consumer_key = \"fUKXD6HbgzvEOTBi4mIrAfWnL\"\n",
    "consumer_secret = \"G6IasvguxSpUgA4GhPPgjr5VeMtGN7bMMIGYMOYyH1em8gWYm9\"\n",
    "access_key = \"217978535-7Ces0VMy4neyTXmPyvG2iMe5UZdlLnBKhL3Zqqnc\"\n",
    "access_secret = \"TszZdJfRQhZbQ7Rsu1tarClV9e11IWDBggHpoA0heLdEJ\"\n",
    "# Pass your twitter credentials to tweepy via its OAuthHandler\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3388e394",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f04bcef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraptweets(search_words, date_since, numTweets, numRuns):\n",
    "    \n",
    "    # Define a for-loop to generate tweets at regular intervals\n",
    "    # We cannot make large API call in one go. Hence, let's try T times\n",
    "    \n",
    "    # Define a pandas dataframe to store the date:\n",
    "    db_tweets = pd.DataFrame(columns = ['username', 'location', 'profileurl','isdefault',\n",
    "                                        'totaltweets', 'usercreatedts', 'tweetcreatedts']\n",
    "                                )\n",
    "    program_start = time.time()\n",
    "    for i in range(0, numRuns):\n",
    "        # We will time how long it takes to scrape tweets for each run:\n",
    "        start_run = time.time()\n",
    "        \n",
    "        # Collect tweets using the Cursor object\n",
    "        # .Cursor() returns an object that you can iterate or loop over to access the data collected.\n",
    "        # Each item in the iterator has various attributes that you can access to get information about each tweet\n",
    "        tweets = tweepy.Cursor(api.search_tweets, q='*', lang=\"en\", tweet_mode='extended').items(numTweets)\n",
    "# Store these tweets into a python list\n",
    "        tweet_list = [tweet for tweet in tweets]\n",
    "# Obtain the following info (methods to call them out):\n",
    "        # user.screen_name - twitter handle\n",
    "        # user.description - description of account\n",
    "        # user.location - where is he tweeting from\n",
    "        # user.friends_count - no. of other users that user is following (following)\n",
    "        # user.followers_count - no. of other users who are following this user (followers)\n",
    "        # user.statuses_count - total tweets by user\n",
    "        # user.created_at - when the user account was created\n",
    "        # created_at - when the tweet was created\n",
    "        # retweet_count - no. of retweets\n",
    "        # (deprecated) user.favourites_count - probably total no. of tweets that is favourited by user\n",
    "        # retweeted_status.full_text - full text of the tweet\n",
    "        # tweet.entities['hashtags'] - hashtags in the tweet\n",
    "# Begin scraping the tweets individually:\n",
    "        noTweets = 0\n",
    "        for tweet in tweet_list:\n",
    "        # Pull the values\n",
    "            username = tweet.user.screen_name\n",
    "            #acctdesc = tweet.user.description\n",
    "            location = tweet.user.location\n",
    "            profileurl = tweet.user.profile_image_url_https\n",
    "            isdefault = tweet.user.default_profile_image\n",
    "            totaltweets = tweet.user.statuses_count\n",
    "            usercreatedts = tweet.user.created_at\n",
    "            tweetcreatedts = tweet.created_at\n",
    "#             retweetcount = tweet.retweet_count\n",
    "#             hashtags = tweet.entities['hashtags']\n",
    "    # Add the 11 variables to the empty list - ith_tweet:\n",
    "            ith_tweet = [username, location, profileurl, isdefault,totaltweets,\n",
    "                         usercreatedts, tweetcreatedts]\n",
    "# Append to dataframe - db_tweets\n",
    "            db_tweets.loc[len(db_tweets)] = ith_tweet\n",
    "# increase counter - noTweets  \n",
    "            noTweets += 1\n",
    "\n",
    "                # Run ended:\n",
    "        end_run = time.time()\n",
    "        duration_run = round((end_run-start_run)/60, 2)\n",
    "\n",
    "        print('no. of tweets scraped for run {} is {}'.format(i + 1, noTweets))\n",
    "        print('time take for {} run to complete is {} mins'.format(i+1, duration_run))\n",
    "\n",
    "        time.sleep(920) #15 minute sleep time\n",
    "# Once all runs have completed, save them to a single csv file:\n",
    "    # Obtain timestamp in a readable format\n",
    "    to_csv_timestamp = datetime.today().strftime('%Y%m%d_%H%M%S')\n",
    "    # Define working path and filename\n",
    "    path = os.getcwd()\n",
    "    filename = path + '/data/' + to_csv_timestamp + '_sahkprotests_tweets.csv'\n",
    "    # Store dataframe in csv with creation date timestamp\n",
    "    db_tweets.to_csv(filename, index = False)\n",
    "\n",
    "    program_end = time.time()\n",
    "    print('Scraping has completed!')\n",
    "    print('Total time taken to scrap is {} minutes.'.format(round(program_end - program_start)/60, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a5f7939",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 1 is 2500\n",
      "time take for 1 run to complete is 15.22 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 2 is 2500\n",
      "time take for 2 run to complete is 15.18 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 3 is 2500\n",
      "time take for 3 run to complete is 15.3 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 4 is 2500\n",
      "time take for 4 run to complete is 15.3 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 5 is 2500\n",
      "time take for 5 run to complete is 15.44 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 6 is 2500\n",
      "time take for 6 run to complete is 15.4 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 7 is 2500\n",
      "time take for 7 run to complete is 15.45 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 8 is 2500\n",
      "time take for 8 run to complete is 15.46 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 9 is 2500\n",
      "time take for 9 run to complete is 15.72 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 10 is 2500\n",
      "time take for 10 run to complete is 15.55 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 11 is 2500\n",
      "time take for 11 run to complete is 15.66 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 12 is 2500\n",
      "time take for 12 run to complete is 15.79 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 13 is 2500\n",
      "time take for 13 run to complete is 15.76 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 14 is 2500\n",
      "time take for 14 run to complete is 15.81 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 15 is 2500\n",
      "time take for 15 run to complete is 16.09 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 16 is 2500\n",
      "time take for 16 run to complete is 16.03 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 17 is 2500\n",
      "time take for 17 run to complete is 15.95 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 18 is 2500\n",
      "time take for 18 run to complete is 16.11 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 19 is 2500\n",
      "time take for 19 run to complete is 16.18 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 20 is 2500\n",
      "time take for 20 run to complete is 16.07 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 21 is 2500\n",
      "time take for 21 run to complete is 15.82 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 22 is 2500\n",
      "time take for 22 run to complete is 16.24 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 23 is 2500\n",
      "time take for 23 run to complete is 16.28 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 24 is 2500\n",
      "time take for 24 run to complete is 16.45 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 25 is 2500\n",
      "time take for 25 run to complete is 16.28 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 26 is 2500\n",
      "time take for 26 run to complete is 16.48 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 27 is 2500\n",
      "time take for 27 run to complete is 16.36 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 28 is 2500\n",
      "time take for 28 run to complete is 16.54 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 29 is 2500\n",
      "time take for 29 run to complete is 16.57 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 30 is 2500\n",
      "time take for 30 run to complete is 16.59 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 31 is 2500\n",
      "time take for 31 run to complete is 16.66 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 32 is 2500\n",
      "time take for 32 run to complete is 16.67 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 33 is 2500\n",
      "time take for 33 run to complete is 16.78 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 34 is 2500\n",
      "time take for 34 run to complete is 16.88 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 35 is 2500\n",
      "time take for 35 run to complete is 16.89 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 36 is 2500\n",
      "time take for 36 run to complete is 16.92 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 37 is 2500\n",
      "time take for 37 run to complete is 16.94 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 38 is 2500\n",
      "time take for 38 run to complete is 16.92 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 39 is 2500\n",
      "time take for 39 run to complete is 16.93 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 40 is 2500\n",
      "time take for 40 run to complete is 17.09 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 41 is 2500\n",
      "time take for 41 run to complete is 17.08 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 42 is 2500\n",
      "time take for 42 run to complete is 17.14 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 43 is 2500\n",
      "time take for 43 run to complete is 17.2 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 44 is 2500\n",
      "time take for 44 run to complete is 17.21 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 45 is 2500\n",
      "time take for 45 run to complete is 17.26 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 46 is 2500\n",
      "time take for 46 run to complete is 17.39 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 47 is 2500\n",
      "time take for 47 run to complete is 17.41 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 48 is 2500\n",
      "time take for 48 run to complete is 17.99 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 49 is 2500\n",
      "time take for 49 run to complete is 17.55 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 50 is 2500\n",
      "time take for 50 run to complete is 17.67 mins\n",
      "Scraping has completed!\n",
      "Total time taken to scrap is 1586.35 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Initialise these variables:\n",
    "#search_words = \"#hongkong OR #hkprotests OR #freehongkong OR #hongkongprotests OR #hkpolicebrutality OR #antichinazi OR #standwithhongkong OR #hkpolicestate OR #HKpoliceterrorist OR #standwithhk OR #hkpoliceterrorism\"\n",
    "date_since = \"2019-11-03\"\n",
    "numTweets = 2500\n",
    "numRuns = 50\n",
    "# Call the function scraptweets\n",
    "scraptweets(search_words, date_since, numTweets, numRuns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e8862cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7e443875",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('~/Desktop/merged_age_gender_race.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c322e13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_age_users = data.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8aa44cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172268,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['screen.name'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a101cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ffcaf9ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'age', 'name', 'screen.name', 'pred_gender'], dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9511b008",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(data.columns[[0, 2]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d86f0af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.age.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7727fde8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>age</th>\n",
       "      <th>name</th>\n",
       "      <th>screen.name</th>\n",
       "      <th>pred_gender</th>\n",
       "      <th>age_bins</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_bins</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(14, 24]</th>\n",
       "      <td>5821</td>\n",
       "      <td>5821</td>\n",
       "      <td>5821</td>\n",
       "      <td>5821</td>\n",
       "      <td>5805</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(24, 34]</th>\n",
       "      <td>39650</td>\n",
       "      <td>39650</td>\n",
       "      <td>39649</td>\n",
       "      <td>39649</td>\n",
       "      <td>39562</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(34, 44]</th>\n",
       "      <td>38255</td>\n",
       "      <td>38255</td>\n",
       "      <td>38254</td>\n",
       "      <td>38254</td>\n",
       "      <td>38214</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(44, 54]</th>\n",
       "      <td>8982</td>\n",
       "      <td>8982</td>\n",
       "      <td>8982</td>\n",
       "      <td>8982</td>\n",
       "      <td>8976</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(54, 64]</th>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0    age   name  screen.name  pred_gender age_bins\n",
       "age_bins                                                             \n",
       "(14, 24]        5821   5821   5821         5821         5805      NaN\n",
       "(24, 34]       39650  39650  39649        39649        39562      NaN\n",
       "(34, 44]       38255  38255  38254        38254        38214      NaN\n",
       "(44, 54]        8982   8982   8982         8982         8976      NaN\n",
       "(54, 64]        2008   2008   2008         2008         2008      NaN"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['age_bins'] = pd.cut(data.age,bins = [14,24,34,44,54,64,75])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "92045cac",
   "metadata": {},
   "outputs": [],
   "source": [
    " data = data.groupby(['age_bins']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "21628342",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age_percent'] = data['age'].div(85807).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ca6b820d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = '(14-24]', '', 'Dogs', 'Logs'\n",
    "sizes = [15, 30, 45, 10]\n",
    "explode = (0, 0.1, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a12caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgCyberGarrett\n",
      "from:AgCyberGarrett\n",
      "hg_eric\n",
      "from:hg_eric\n",
      "ValarezoSilvia\n",
      "from:ValarezoSilvia\n",
      "slskdidl629\n",
      "from:slskdidl629\n",
      "ClimateKenya254\n",
      "from:ClimateKenya254\n",
      "DaisyLeoncio\n",
      "from:DaisyLeoncio\n",
      "ywaiaqualife\n",
      "from:ywaiaqualife\n",
      "ZaxxonGalaxian\n",
      "from:ZaxxonGalaxian\n",
      "Miriamachieng21\n",
      "from:Miriamachieng21\n",
      "MAB1961A\n",
      "from:MAB1961A\n",
      "AbuProdhan\n",
      "from:AbuProdhan\n",
      "DorcasRutunda\n",
      "from:DorcasRutunda\n",
      "dhahabu\n",
      "from:dhahabu\n",
      "pwpgarden\n",
      "from:pwpgarden\n",
      "thisdaringdan\n",
      "from:thisdaringdan\n",
      "DBrothers6\n",
      "from:DBrothers6\n",
      "CanGeoEdu\n",
      "from:CanGeoEdu\n",
      "efiresilience\n",
      "from:efiresilience\n",
      "nksnhle\n",
      "from:nksnhle\n",
      "Mataaya1\n",
      "from:Mataaya1\n",
      "BinagekarAnusha\n",
      "from:BinagekarAnusha\n",
      "mnarbs\n",
      "from:mnarbs\n",
      "K178aa\n",
      "from:K178aa\n",
      "Bornscorer\n",
      "from:Bornscorer\n",
      "xuVn1OgFGaCpvDQ\n",
      "from:xuVn1OgFGaCpvDQ\n",
      "Roy_Okonji\n",
      "from:Roy_Okonji\n",
      "Connect4Climate\n",
      "from:Connect4Climate\n",
      "Assuzamukunda\n",
      "from:Assuzamukunda\n",
      "JudyKosgei\n",
      "from:JudyKosgei\n",
      "GEngida56\n",
      "from:GEngida56\n",
      "locagro\n",
      "from:locagro\n",
      "IvokainKrieg\n",
      "from:IvokainKrieg\n",
      "GDSAofficial1\n",
      "from:GDSAofficial1\n",
      "KatjaBessonova\n",
      "from:KatjaBessonova\n",
      "aitkakaaki\n",
      "from:aitkakaaki\n",
      "EliasKimaru\n",
      "from:EliasKimaru\n",
      "originalCeGe\n",
      "from:originalCeGe\n",
      "WIongh\n",
      "from:WIongh\n",
      "GafarOdubote\n",
      "from:GafarOdubote\n",
      "CalvinNicholaus\n",
      "from:CalvinNicholaus\n",
      "EadaionAya\n",
      "from:EadaionAya\n",
      "dreamworld2222\n",
      "from:dreamworld2222\n",
      "GraceOkelloKe\n",
      "from:GraceOkelloKe\n",
      "SandraGinev\n",
      "from:SandraGinev\n",
      "tintedsushi\n",
      "from:tintedsushi\n",
      "GailWadsworth\n",
      "from:GailWadsworth\n",
      "SplashSoup\n",
      "from:SplashSoup\n",
      "MrsMajorHoff\n",
      "from:MrsMajorHoff\n",
      "akinyichemutai\n",
      "from:akinyichemutai\n",
      "vivienne_mccone\n",
      "from:vivienne_mccone\n",
      "flinky478\n",
      "from:flinky478\n",
      "SimiyuCaleb11\n",
      "from:SimiyuCaleb11\n",
      "LoladzeLasha\n",
      "from:LoladzeLasha\n",
      "habitatTNT\n",
      "from:habitatTNT\n",
      "MissNasike\n",
      "from:MissNasike\n",
      "james_trezise\n",
      "from:james_trezise\n",
      "AMITAVAKAR14\n",
      "from:AMITAVAKAR14\n",
      "nazhatskhan\n",
      "from:nazhatskhan\n",
      "Piagi\n",
      "from:Piagi\n",
      "Santiag68690262\n",
      "from:Santiag68690262\n",
      "Sasajewun\n",
      "from:Sasajewun\n",
      "mongabay\n",
      "from:mongabay\n",
      "Meldawson6\n",
      "from:Meldawson6\n",
      "VisualPersist\n",
      "from:VisualPersist\n",
      "vini_adelia\n",
      "from:vini_adelia\n",
      "esaSolar_Energy\n",
      "from:esaSolar_Energy\n",
      "gaviotablanka\n",
      "from:gaviotablanka\n",
      "SustainabiliTT\n",
      "from:SustainabiliTT\n",
      "natialobank\n",
      "from:natialobank\n",
      "jemang\n",
      "from:jemang\n",
      "FoodForward_MD\n",
      "from:FoodForward_MD\n",
      "kassangasshop\n",
      "from:kassangasshop\n",
      "4dz5TVHyABpdoKt\n",
      "from:4dz5TVHyABpdoKt\n",
      "NuriaStore\n",
      "from:NuriaStore\n",
      "ChutneysAndJams\n",
      "from:ChutneysAndJams\n",
      "LorenaTrejoN\n",
      "from:LorenaTrejoN\n",
      "SFHongKong\n",
      "from:SFHongKong\n",
      "ForestRightsAct\n",
      "from:ForestRightsAct\n",
      "Johnharveywells\n",
      "from:Johnharveywells\n",
      "mosomtai\n",
      "from:mosomtai\n",
      "kipranjohn\n",
      "from:kipranjohn\n",
      "sayedsara21\n",
      "from:sayedsara21\n",
      "NYpoet\n",
      "from:NYpoet\n",
      "magovl\n",
      "from:magovl\n",
      "refinnejretsil\n",
      "from:refinnejretsil\n",
      "GabrielaCordon\n",
      "from:GabrielaCordon\n",
      "SophieFern\n",
      "from:SophieFern\n",
      "JoannaMMeyer\n",
      "from:JoannaMMeyer\n",
      "RoyTroy9j77\n",
      "from:RoyTroy9j77\n",
      "itsmathewsnr_k\n",
      "from:itsmathewsnr_k\n",
      "FCNMedNE\n",
      "from:FCNMedNE\n",
      "NopiaRide\n",
      "from:NopiaRide\n",
      "olaideolawuwo\n",
      "from:olaideolawuwo\n",
      "KathleenGSmart\n",
      "from:KathleenGSmart\n",
      "dervinpagan\n",
      "from:dervinpagan\n",
      "shashank7800124\n",
      "from:shashank7800124\n",
      "choco0724d\n",
      "from:choco0724d\n",
      "GilroyCorreia\n",
      "from:GilroyCorreia\n",
      "ArnfinnNygaard\n",
      "from:ArnfinnNygaard\n",
      "NuvoConsulting\n",
      "from:NuvoConsulting\n",
      "tasjagab\n",
      "from:tasjagab\n",
      "aalamaramngo\n",
      "from:aalamaramngo\n",
      "princebashbal\n",
      "from:princebashbal\n",
      "SimonChinYee\n",
      "from:SimonChinYee\n",
      "G_Abdulazeez\n",
      "from:G_Abdulazeez\n",
      "karissalund\n",
      "from:karissalund\n",
      "ferreiraanthon1\n",
      "from:ferreiraanthon1\n",
      "GreenfuelA\n",
      "from:GreenfuelA\n",
      "jewelsfrazier68\n",
      "from:jewelsfrazier68\n",
      "YazanKamarul\n",
      "from:YazanKamarul\n",
      "AAlanis_67\n",
      "from:AAlanis_67\n",
      "ing_lele\n",
      "from:ing_lele\n",
      "New_Alexie\n",
      "from:New_Alexie\n",
      "BSchlichting\n",
      "from:BSchlichting\n",
      "nhana_G\n",
      "from:nhana_G\n",
      "reparamexico\n",
      "from:reparamexico\n",
      "VeroTakesAction\n",
      "from:VeroTakesAction\n",
      "hultgrenrb\n",
      "from:hultgrenrb\n",
      "dominicbosco2\n",
      "from:dominicbosco2\n",
      "ffrenchthegreat\n",
      "from:ffrenchthegreat\n",
      "RockyDawuni\n",
      "from:RockyDawuni\n",
      "ndngenuity\n",
      "from:ndngenuity\n",
      "adnanmahar098\n",
      "from:adnanmahar098\n",
      "mynjbrn\n",
      "from:mynjbrn\n",
      "La_network\n",
      "from:La_network\n",
      "sophiahidelisa\n",
      "from:sophiahidelisa\n",
      "Oscar_T_B\n",
      "from:Oscar_T_B\n",
      "talieh_wm\n",
      "from:talieh_wm\n",
      "SistiPresidente\n",
      "from:SistiPresidente\n",
      "trop_forester\n",
      "from:trop_forester\n",
      "financeandKM\n",
      "from:financeandKM\n",
      "simplemama2013\n",
      "from:simplemama2013\n",
      "kjmilla\n",
      "from:kjmilla\n",
      "ARIFULHAQUE_17\n",
      "from:ARIFULHAQUE_17\n",
      "Samrentads\n",
      "from:Samrentads\n",
      "imperfectwomen\n",
      "from:imperfectwomen\n",
      "spfcpakistan\n",
      "from:spfcpakistan\n",
      "a_manuelli\n",
      "from:a_manuelli\n",
      "Akillideli9\n",
      "from:Akillideli9\n",
      "ipmsdl_\n",
      "from:ipmsdl_\n",
      "sincere_too\n",
      "from:sincere_too\n",
      "yaomoisekatumbi\n",
      "from:yaomoisekatumbi\n",
      "etemesietemesi\n",
      "from:etemesietemesi\n",
      "Cylexi\n",
      "from:Cylexi\n",
      "BioDiverseNet\n",
      "from:BioDiverseNet\n",
      "AidaGreenbury\n",
      "from:AidaGreenbury\n",
      "FayLucia\n",
      "from:FayLucia\n",
      "NICOcolletier\n",
      "from:NICOcolletier\n",
      "gsinl\n",
      "from:gsinl\n",
      "Yoenoes_Mohd\n",
      "from:Yoenoes_Mohd\n",
      "Mwizeere\n",
      "from:Mwizeere\n",
      "maitaperiodista\n",
      "from:maitaperiodista\n",
      "TaseCdenD\n",
      "from:TaseCdenD\n",
      "TheRohanGhiya\n",
      "from:TheRohanGhiya\n",
      "ConnectSDGs\n",
      "from:ConnectSDGs\n",
      "tree_joe\n",
      "from:tree_joe\n",
      "ScholaDecaprado\n",
      "from:ScholaDecaprado\n"
     ]
    }
   ],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "for username in usernames:\n",
    "    \n",
    "    print(username)\n",
    "# Creating list to append tweet data to\n",
    "    tweets_list1 = []\n",
    "\n",
    "    query = f'from:{username}'\n",
    "    print(query)\n",
    "    # Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "    for i,tweet in enumerate(sntwitter.TwitterSearchScraper(query).get_items()):\n",
    "        if i>1000:\n",
    "            break\n",
    "        tweets_list1.append([tweet.user.username, tweet.date, tweet.id,tweet.user.location])\n",
    "\n",
    "    # Creating a dataframe from the tweets list above \n",
    "    tweets_df1 = pd.DataFrame(tweets_list1, columns=['Username','Datetime', 'Tweet Id','Location'])\n",
    "    to_csv_timestamp = datetime.today().strftime('%Y%m%d_%H%M%S')\n",
    "    # Define working path and filename\n",
    "    path = os.getcwd()\n",
    "    filename = path + '/data/' + username + '.csv'\n",
    "    # Store dataframe in csv with creation date timestamp\n",
    "    tweets_df1.to_csv(filename, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06660791",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34c8a83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
